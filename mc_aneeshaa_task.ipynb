{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kC7vsWJuR2CN",
        "FArTrrejR8nC",
        "vh_uIoZyTHqo",
        "Nkn-0UAOSdzA",
        "xg_wFQr8TVDa"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "kC7vsWJuR2CN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import average_precision_score, make_scorer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.ticker as mticker\n",
        "from IPython.display import display\n",
        "\n",
        "OUTPUT_FIGURES_DIR = os.path.join(\"reports\", \"figures\")\n",
        "plt.style.use('ggplot')\n",
        "os.makedirs(OUTPUT_FIGURES_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "2mqDnAJ1R6CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data ingestion\n",
        "\n",
        "Upload data and update fil_path value with path of data file"
      ],
      "metadata": {
        "id": "FArTrrejR8nC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_bank_data() -> pd.DataFrame:\n",
        "    file_path = 'bank-full.csv'\n",
        "    print(f\"Attempting to load data from local file: {file_path}\")\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, sep=';')\n",
        "        print(f\"Data loaded successfully from {file_path}. Shape: {df.shape}\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_path}' was not found. Please ensure it's in the correct directory.\")\n",
        "        return pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during data loading: {e}\")\n",
        "        return pd.DataFrame()"
      ],
      "metadata": {
        "id": "jeUswKyfSEzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    if df.empty:\n",
        "        return df\n",
        "    df_prepared = df.copy()\n",
        "\n",
        "    if 'day' in df_prepared.columns:\n",
        "        df_prepared.rename(columns={'day': 'day_of_month'}, inplace=True)\n",
        "        print(\"Renamed 'day' to 'day_of_month' for clarity.\")\n",
        "\n",
        "    print(\"No NaN values found in df.info(), so skipping NaN filling step.\")\n",
        "    constant_value_cols = [col for col in df_prepared.columns if df_prepared[col].nunique() == 1]\n",
        "\n",
        "    if constant_value_cols:\n",
        "        df_prepared.drop(columns=constant_value_cols, inplace=True)\n",
        "        print(f\"Dropped columns with constant values: {constant_value_cols}\")\n",
        "\n",
        "    return df_prepared"
      ],
      "metadata": {
        "id": "EEnxpP0TSGVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "vh_uIoZyTHqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Performs feature engineering on the dataset.\n",
        "    This function is now called for EDA purposes but the engineered features\n",
        "    are not used in the final model training to align with user request.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df\n",
        "    df_engineered = df.copy()\n",
        "    print(\"--- Performing Feature Engineering for Insights ---\")\n",
        "    if 'y' in df_engineered.columns and df_engineered['y'].dtype == 'object':\n",
        "        df_engineered['y'] = df_engineered['y'].map({'no': 0, 'yes': 1})\n",
        "    df_engineered['num_existing_loans'] = (df_engineered['housing'] == 'yes').astype(int).astype('category')\n",
        "    df_engineered['has_any_loan_or_default'] = ((df_engineered['num_existing_loans'] == 1) | \\\n",
        "                                               (df_engineered['default'] == 'yes')).astype(int).astype('category')\n",
        "    bins_age = [0, 25, 35, 45, 55, 65, 100]\n",
        "    labels_age = ['<25', '25-34', '35-44', '45-54', '55-64', '65+']\n",
        "    df_engineered['age_group'] = pd.cut(df_engineered['age'], bins=bins_age, labels=labels_age, right=False)\n",
        "    df_engineered['is_no_fixed_income'] = (df_engineered['job'].isin(['student','retired','unemployed'])).astype(int).astype('category')\n",
        "    df_engineered['balance_group'] = pd.qcut(df_engineered['balance'] + 0.001, q=5, labels=['Bal_Q1', 'Bal_Q2', 'Bal_Q3', 'Bal_Q4', 'Bal_Q5'])\n",
        "    df_engineered['is_negative_balance'] = (df_engineered['balance'] < 0).astype(int).astype('category')\n",
        "    df_engineered['was_previously_contacted'] = (df_engineered['pdays'] != -1).astype(int).astype('category')\n",
        "    spring_summer_months = ['apr', 'may', 'jun', 'jul', 'aug']\n",
        "    df_engineered['is_spring_summer_contact'] = df_engineered['month'].isin(spring_summer_months).astype(int).astype('category')\n",
        "    df_engineered['total_contacts'] = df_engineered['previous'] + df_engineered['campaign']\n",
        "    month_mapping = {\n",
        "        'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
        "        'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
        "    }\n",
        "    df_engineered['month_numeric'] = df_engineered['month'].map(month_mapping)\n",
        "    df_engineered['day_of_week'] = (pd.to_datetime(2023).tz_localize(None) +\n",
        "                                     pd.to_timedelta(df_engineered['month_numeric'] * 30 + df_engineered['day_of_month'], unit='D')\n",
        "                                    ).dt.day_name()\n",
        "    df_engineered.drop('month_numeric', axis=1, inplace=True)\n",
        "    print(\"Engineered new features: 'num_existing_loans', 'has_any_loan_or_default', 'age_group', 'is_no_fixed_income', 'balance_group', 'is_negative_balance', 'was_previously_contacted', 'is_spring_summer_contact', 'total_contacts', and 'day_of_week'.\")\n",
        "    return df_engineered\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0bUv4w9wTHZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "Nkn-0UAOSdzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_eda(df: pd.DataFrame, output_dir: str):\n",
        "    \"\"\"\n",
        "    Generates and saves exploratory data analysis plots for original features.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Performing Exploratory Data Analysis (EDA) on Original Features ---\")\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    if df_copy['y'].dtype == 'object':\n",
        "        df_copy['y'] = df_copy['y'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "    numerical_cols = df_copy.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    categorical_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "    if 'y' in numerical_cols:\n",
        "        numerical_cols.remove('y')\n",
        "    if 'y' in categorical_cols:\n",
        "        categorical_cols.remove('y')\n",
        "\n",
        "    # --- Plot 1: Target Variable Distribution (Pie Chart) ---\n",
        "    target_counts = df_copy['y'].value_counts()\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.pie(target_counts, labels=target_counts.index, autopct='%1.1f%%', startangle=90, colors=['skyblue', 'lightcoral'])\n",
        "    plt.title('Distribution of Target Variable (y)')\n",
        "    plt.axis('equal')\n",
        "    plt.savefig(os.path.join(output_dir, 'target_distribution.png'))\n",
        "    plt.close()\n",
        "    print(\"Saved target distribution plot.\")\n",
        "\n",
        "    # Plot 2: Categorical Features vs. Target (Percentage Plots)\n",
        "    if categorical_cols:\n",
        "        num_plots = len(categorical_cols)\n",
        "        fig_rows = int(np.ceil(num_plots / 3))\n",
        "        plt.figure(figsize=(12, 4 * fig_rows))\n",
        "        for i, col in enumerate(categorical_cols):\n",
        "            # Calculate the percentages, explicitly setting observed=False to suppress the FutureWarning\n",
        "            temp_df = df_copy.groupby(col, observed=False)['y'].value_counts(normalize=True).mul(100).rename('percentage').reset_index()\n",
        "\n",
        "            plt.subplot(fig_rows, 3, i + 1)\n",
        "            ax = sns.barplot(x=col, y='percentage', hue='y', data=temp_df, palette=['lightcoral', 'skyblue'])\n",
        "\n",
        "            # Add percentage labels on top of the bars\n",
        "            for p in ax.patches:\n",
        "                height = p.get_height()\n",
        "                ax.text(p.get_x() + p.get_width() / 2., height + 1,\n",
        "                        f'{height:.1f}%', ha=\"center\", fontsize=8)\n",
        "\n",
        "            plt.title(f'Subscription Rate by {col}')\n",
        "            plt.xlabel(col)\n",
        "            plt.ylabel('Percentage (%)')\n",
        "            plt.xticks(rotation=45, ha='right')\n",
        "            ax.set_ylim(0, 100) # Set y-axis to a fixed range\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, 'all_categorical_features_vs_target_percentage.png'))\n",
        "        plt.close()\n",
        "        print(f\"Saved percentage plots for {len(categorical_cols)} original categorical features vs. target.\")\n",
        "    else:\n",
        "        print(\"No categorical features to plot against target.\")\n",
        "\n",
        "    # Plot 3: Correlation Matrix Heatmap for ALL Numerical Features\n",
        "    numerical_cols_for_corr = [col for col in numerical_cols if col in df_copy.columns and df_copy[col].dtype in ['int64', 'float64']]\n",
        "    if 'y' not in numerical_cols_for_corr:\n",
        "        if 'y' in df_copy.columns and df_copy['y'].dtype in ['int64', 'float64']:\n",
        "             numerical_cols_for_corr.append('y')\n",
        "\n",
        "    if numerical_cols_for_corr:\n",
        "        correlation_matrix = df_copy[numerical_cols_for_corr].corr()\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "        plt.title('Correlation Matrix of All Original Numerical Features')\n",
        "        plt.savefig(os.path.join(output_dir, 'all_numerical_features_correlation_matrix.png'))\n",
        "        plt.close()\n",
        "        print(\"Saved correlation matrix heatmap for all original numerical features.\")\n",
        "    else:\n",
        "        print(\"No numerical features found for correlation matrix plot.\")\n",
        "\n",
        "    # Plot 4: Duration Distribution vs. Subscription Status\n",
        "    if 'duration' in df_copy.columns and 'y' in df_copy.columns:\n",
        "        df_copy_for_plot = df_copy.copy()\n",
        "        df_copy_for_plot['subscribed_status'] = df_copy_for_plot['y'].map({0: 'Not Subscribed', 1: 'Subscribed'})\n",
        "        sns.set_style(\"whitegrid\")\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        sns.kdeplot(data=df_copy_for_plot, x='duration', hue='subscribed_status', fill=True, common_norm=False, palette=['lightcoral', 'skyblue'])\n",
        "        mean_duration_no = df_copy_for_plot[df_copy_for_plot['y'] == 0]['duration'].mean()\n",
        "        mean_duration_yes = df_copy_for_plot[df_copy_for_plot['y'] == 1]['duration'].mean()\n",
        "        plt.axvline(x=mean_duration_no, color='darkred', linestyle='--', label=f'Avg. Not Subscribed: {mean_duration_no:.2f}s')\n",
        "        plt.axvline(x=mean_duration_yes, color='darkblue', linestyle='--', label=f'Avg. Subscribed: {mean_duration_yes:.2f}s')\n",
        "        plt.title('Distribution of Last Contact Duration by Subscription Status', fontsize=16)\n",
        "        plt.xlabel('Last Contact Duration (seconds)', fontsize=12)\n",
        "        plt.ylabel('Density', fontsize=12)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, 'duration_distribution.png'))\n",
        "        plt.close()\n",
        "        print(\"Saved duration distribution plot with mean lines.\")\n",
        "    else:\n",
        "        print(\"Skipping duration distribution plot: 'duration' or 'y' column not found.\")\n"
      ],
      "metadata": {
        "id": "EBzt9KaNTRUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the plots generated -\n",
        "\n",
        "**Insights**\n",
        "\n",
        "1. **Target Audience Focus:** The target distribution plot shows that only a small percentage (11.7%) of customers subscribe to a term deposit. This highlights the need to carefully target marketing efforts towards segments with a higher propensity to subscribe.\n",
        "\n",
        "2. **Identify Promising Segments (from Categorical Plots):**\n",
        "\n",
        "    a. Customers who are retired or students have significantly higher subscription\n",
        "    rates. Marketing efforts could be specifically tailored to these groups.\n",
        "\n",
        "    b. Customers with a tertiary education or who are single also show relatively higher subscription rates.\n",
        "\n",
        "    c. The balance_group plot suggests that customers in higher balance quantiles might be more likely to subscribe due to sufficient disposable income.\n",
        "\n",
        "    d. The poutcome plot clearly shows that previous success in a marketing campaign is a strong indicator of future subscription. Focusing on customers with a 'success' in the previous campaign outcome is likely to be highly effective.\n",
        "\n",
        "    e. Certain months (e.g., March, September, October, December) appear to have higher subscription rates, suggesting seasonality in campaign effectiveness.\n",
        "\n",
        "    f. The day_of_week plot can help in optimizing the timing of contact.\n",
        "\n",
        "3. **Avoid Less Promising Segments (from Categorical Plots):**\n",
        "\n",
        "    a. Customers who have defaulted on loans have a very low subscription rate.\n",
        "\n",
        "    b. Using 'unknown' contact methods or contacting people with an 'unknown' previous outcome is associated with lower success rates.\n",
        "\n",
        "4. **Duration Matters (from Duration Plot):**\n",
        "\n",
        "    The duration distribution plot clearly shows that the duration of the last contact is strongly correlated with subscription. Longer calls are more likely to result in a subscription. This suggests that call center scripts and agent training should emphasize engaging customers for a sufficient duration. However, duration is only known *after the call, so it's not a feature that can be used for predictive targeting before the call.* It's more of an insight into the nature of successful interactions.\n",
        "\n",
        "5. **Beware of Correlation (from Correlation Matrix):**\n",
        "\n",
        "    While the correlation matrix primarily shows linear relationships between numerical features,'campaign' and 'previous' are correlated, which is intuitive as more campaigns might lead to more previous contacts.\n",
        "\n",
        "\n",
        "In summary, the plots suggest that targeting retired individuals, students, those with tertiary education, those previously successful in campaigns, and focusing on specific months and days of the week could improve marketing campaign effectiveness. The duration of contact is also a key factor in successful subscriptions and training the call centre executives to provide clear explanation of benefits of subscribing would help."
      ],
      "metadata": {
        "id": "LCJYBlh7aCVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode features"
      ],
      "metadata": {
        "id": "xg_wFQr8TVDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_features(df: pd.DataFrame) -> tuple[pd.DataFrame, list]:\n",
        "    \"\"\"\n",
        "    Encodes only the original categorical features for the model.\n",
        "    \"\"\"\n",
        "    if df.empty:\n",
        "        return df, []\n",
        "    df_encoded = df.copy()\n",
        "    if df_encoded['y'].dtype == 'object':\n",
        "        df_encoded['y'] = df_encoded['y'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "    # We only encode the original features as requested\n",
        "    categorical_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "    categorical_features_lgbm = [col for col in categorical_cols if col in df_encoded.columns]\n",
        "    for col in categorical_features_lgbm:\n",
        "        le = LabelEncoder()\n",
        "        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))\n",
        "    return df_encoded, categorical_features_lgbm"
      ],
      "metadata": {
        "id": "2MQBswgATXTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation mechanism\n",
        "\n",
        "We live in a world of hyperpersonalization. I intend to build something that can recommend the best time to contact someone and if we had product data, also recommend which product to offer a customer.\n",
        "\n",
        "1. Optimal Contact Timing:\n",
        "To achieve this, I have created 'segments' of customers based on their job, marital status, education, poutcome, and age_group attributes. For each segment, the month with the highest conversion rate and day of the month with highest conversion rate is recommended as the best time to contact.\n",
        "\n",
        "2. Contact frequency guidance:\n",
        "Additionally, customers who have already been contacted many times may not be inclined to subscribe. Hence, based on the total number of times they've been contacted before (past and current campaign), I recommend how many more times we likely need to contact them to persuade them to subscribe based on the average number of times people in that cohort need to be contacted before they subscribe.\n",
        "\n",
        "NOTE -\n",
        "\n",
        "1. If we know product details, we can recommend specific products to customers.\n",
        "2. We can tailor offerings/marketing messages based on age/job/marital status etc."
      ],
      "metadata": {
        "id": "dEbtb_IbTaCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bin_age(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "    df_with_age_bin = df.copy()\n",
        "    bins = [0, 25, 35, 45, 55, 65, 100]\n",
        "    labels = ['<25', '25-34', '35-44', '45-54', '55-64', '65+']\n",
        "    df_with_age_bin['age_group'] = pd.cut(df_with_age_bin['age'], bins=bins, labels=labels, right=False)\n",
        "    return df_with_age_bin\n",
        "\n",
        "def calculate_segment_averages(df_train_subscribers: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates average total contacts for successful customers within each segment.\n",
        "    The segment is now defined by job, marital status, education, age group, and poutcome.\n",
        "    \"\"\"\n",
        "    if df_train_subscribers.empty:\n",
        "        return pd.DataFrame(columns=['job', 'marital', 'education', 'poutcome', 'age_group', 'avg_total_contacts'])\n",
        "    df_train_subscribers['total_contacts'] = df_train_subscribers['previous'] + df_train_subscribers['campaign']\n",
        "    segment_columns = ['job', 'marital', 'education', 'poutcome', 'age_group']\n",
        "    segment_averages = df_train_subscribers.groupby(segment_columns, observed=False)['total_contacts'].mean().reset_index()\n",
        "    segment_averages.rename(columns={'total_contacts': 'avg_total_contacts'}, inplace=True)\n",
        "    return segment_averages\n",
        "\n",
        "\n",
        "def calculate_best_contact_info(df_train_all: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates the best month and day_of_month for each segment based on conversion rates.\n",
        "    \"\"\"\n",
        "    if df_train_all.empty:\n",
        "        return pd.DataFrame(columns=['job', 'marital', 'education', 'poutcome', 'age_group', 'best_month', 'best_day'])\n",
        "\n",
        "    df_with_age_bin = bin_age(df_train_all)\n",
        "    segment_columns = ['job', 'marital', 'education', 'poutcome', 'age_group']\n",
        "\n",
        "    # Calculate conversion rates for each month within each segment\n",
        "    month_conversion_rates = df_with_age_bin.groupby(segment_columns + ['month'], observed=False)['y'].mean().reset_index()\n",
        "\n",
        "    # Find the best month for each segment, dropping NaNs to prevent KeyError\n",
        "    idx_best_month = month_conversion_rates.groupby(segment_columns, observed=False)['y'].idxmax().dropna()\n",
        "    best_months = month_conversion_rates.loc[idx_best_month].rename(columns={'y': 'best_month_rate', 'month': 'best_month'})\n",
        "\n",
        "    # Calculate conversion rates for each day within each segment\n",
        "    day_conversion_rates = df_with_age_bin.groupby(segment_columns + ['day_of_month'], observed=False)['y'].mean().reset_index()\n",
        "\n",
        "    # Find the best day for each segment, dropping NaNs to prevent KeyError\n",
        "    idx_best_day = day_conversion_rates.groupby(segment_columns, observed=False)['y'].idxmax().dropna()\n",
        "    best_days = day_conversion_rates.loc[idx_best_day].rename(columns={'y': 'best_day_rate', 'day_of_month': 'best_day'})\n",
        "\n",
        "    best_contact_info = pd.merge(best_months.drop('best_month_rate', axis=1), best_days.drop('best_day_rate', axis=1), on=segment_columns, how='left')\n",
        "    return best_contact_info\n",
        "\n",
        "\n",
        "\n",
        "def create_actionable_recommendations_optimized(results_df: pd.DataFrame, segment_averages: pd.DataFrame, best_contact_info: pd.DataFrame) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Creates tailored recommendations for each customer based on their propensity score and segment-specific insights.\n",
        "    \"\"\"\n",
        "    results_df = bin_age(results_df)\n",
        "    segment_columns = ['job', 'marital', 'education', 'poutcome', 'age_group']\n",
        "\n",
        "    results_with_avg = pd.merge(results_df, segment_averages, on=segment_columns, how='left')\n",
        "    results_with_info = pd.merge(results_with_avg, best_contact_info, on=segment_columns, how='left')\n",
        "\n",
        "    avg_contacts_for_segment_mean = segment_averages['avg_total_contacts'].mean() if not segment_averages.empty else 0\n",
        "    results_with_info['avg_total_contacts'] = results_with_info['avg_total_contacts'].fillna(avg_contacts_for_segment_mean)\n",
        "    results_with_info['additional_contacts_needed'] = (results_with_info['avg_total_contacts'] - results_with_info['total_contacts']).apply(lambda x: max(0, np.ceil(x)))\n",
        "\n",
        "    recommendations = []\n",
        "    for _, row in results_with_info.iterrows():\n",
        "        propensity = row['propensity_to_subscribe']\n",
        "        job = row['job']\n",
        "        poutcome = row['poutcome']\n",
        "        total_contacts = row['total_contacts']\n",
        "        avg_contacts_for_segment = row['avg_total_contacts']\n",
        "        additional_contacts_needed = row['additional_contacts_needed']\n",
        "        best_month = row['best_month']\n",
        "        best_day = row['best_day']\n",
        "\n",
        "        base_rec = f\"Based on a propensity score of {propensity:.2f}, this customer is a strong candidate for a call.\"\n",
        "\n",
        "        if additional_contacts_needed > 0:\n",
        "            contact_freq_rec = f\"They have had fewer contacts ({total_contacts}) than the average successful customer in their cohort ({avg_contacts_for_segment:.2f}). Consider making approximately {int(additional_contacts_needed)} more contact attempts.\"\n",
        "        else:\n",
        "            contact_freq_rec = f\"They have already had enough contacts ({total_contacts}) to be considered in line with the average successful customer in their cohort ({avg_contacts_for_segment:.2f}).\"\n",
        "\n",
        "        # Handle potential NaN values in best_month and best_day\n",
        "        if pd.notna(best_month) and pd.notna(best_day):\n",
        "             contact_timing_rec = f\"Based on historical data for customers like them, the best time to contact would be in {best_month.capitalize()} on day {int(best_day)} of the month.\"\n",
        "        else:\n",
        "            contact_timing_rec = \"Timing recommendations are not available for this customer's segment based on the training data.\"\n",
        "\n",
        "\n",
        "        final_rec = f\"{base_rec} {contact_timing_rec} {contact_freq_rec}\"\n",
        "        recommendations.append(final_rec)\n",
        "\n",
        "    return pd.Series(recommendations, index=results_df.index)"
      ],
      "metadata": {
        "id": "86RCN7uRTbyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training and evaluation\n",
        "\n",
        "We perform hyperparameter tuning with cross validation to get optimal features"
      ],
      "metadata": {
        "id": "d77OMMMuTg4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importance(model, features, output_dir, file_suffix):\n",
        "    \"\"\"\n",
        "    Plots the top N feature importances from a trained LightGBM model as percentages.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Plotting Feature Importance for {file_suffix} Model ---\")\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': features,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values(by='importance', ascending=False)\n",
        "\n",
        "    # Calculate importance as a percentage of the total sum\n",
        "    total_importance = importance_df['importance'].sum()\n",
        "    importance_df['importance_percent'] = (importance_df['importance'] / total_importance) * 100\n",
        "\n",
        "    # Display top 10 features with percentage values\n",
        "    display(importance_df[['feature', 'importance_percent']].head(10))\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='importance_percent', y='feature', data=importance_df.head(10))\n",
        "    plt.title(f'Top 10 Feature Importances ({file_suffix} Model)')\n",
        "    plt.xlabel('Importance (%)')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.gca().xaxis.set_major_formatter(mticker.PercentFormatter()) # Format x-axis as percentage\n",
        "    plt.tight_layout()\n",
        "    output_path = os.path.join(output_dir, f'feature_importance_{file_suffix}.png')\n",
        "    plt.savefig(output_path)\n",
        "    plt.close()\n",
        "    print(f\"Feature importance plot saved to '{output_path}'.\")\n"
      ],
      "metadata": {
        "id": "-jpaUe2O5E8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X_train_val, X_test, y_train_val, y_test, X_test_original, output_dir, categorical_features_lgbm, model_name_suffix: str):\n",
        "\n",
        "    print(f\"\\n--- Starting Model Training and Evaluation for {model_name_suffix} Model ---\")\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
        "    )\n",
        "    print(f\"Data split: Train={X_train.shape}, Val={X_val.shape}, Test={X_test.shape}\")\n",
        "    lgb_clf = lgb.LGBMClassifier(objective='binary', random_state=42, n_jobs=-1, force_col_wise=True, verbose=-1)\n",
        "    imbalance_ratio = y_train_val.value_counts()[0] / y_train_val.value_counts()[1]\n",
        "    param_distributions = {\n",
        "        'n_estimators': [500, 800, 1000], 'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "        'num_leaves': [20, 31, 40, 50], 'max_depth': [5, 8, 10], 'min_child_samples': [10, 20, 30, 50, 100],\n",
        "        'subsample': [0.6, 0.8, 1.0], 'colsample_bytree': [0.6, 0.8, 1.0], 'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
        "        'reg_lambda': [0, 0.1, 0.5, 1.0], 'class_weight': [None, 'balanced'],\n",
        "        'scale_pos_weight': [1, imbalance_ratio, imbalance_ratio * 0.5, imbalance_ratio * 1.5]\n",
        "    }\n",
        "    aucpr_scorer = make_scorer(average_precision_score)\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    random_search = RandomizedSearchCV(\n",
        "        estimator=lgb_clf, param_distributions=param_distributions,\n",
        "        n_iter=15, scoring=aucpr_scorer, cv=skf, verbose=1, random_state=42\n",
        "    )\n",
        "    print(\"Starting RandomizedSearchCV for LightGBM tuning with Early Stopping...\")\n",
        "    early_stopping_rounds = 20\n",
        "    random_search.fit(X_train_val, y_train_val,\n",
        "                      eval_set=[(X_val, y_val)],\n",
        "                      eval_metric='average_precision',\n",
        "                      callbacks=[lgb.early_stopping(early_stopping_rounds, verbose=False)],\n",
        "                      categorical_feature=categorical_features_lgbm)\n",
        "    best_lgb_model = random_search.best_estimator_\n",
        "    print(\"\\nBest hyperparameters found:\", random_search.best_params_)\n",
        "    print(\"Best cross-validation AUC-PR score:\", random_search.best_score_)\n",
        "    y_pred_proba_test = best_lgb_model.predict_proba(X_test)[:, 1]\n",
        "    test_aucpr = average_precision_score(y_test, y_pred_proba_test)\n",
        "    print(f\"\\nFinal Test Set AUC-PR for {model_name_suffix} model: {test_aucpr:.4f}\")\n",
        "\n",
        "    # Plot feature importance\n",
        "    plot_feature_importance(best_lgb_model, X_train_val.columns.tolist(), output_dir, model_name_suffix)\n",
        "\n",
        "    return best_lgb_model, y_pred_proba_test, test_aucpr\n"
      ],
      "metadata": {
        "id": "FTNMJISqTk9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create propensity file with recommendation"
      ],
      "metadata": {
        "id": "fmnAkUG1V3dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_propensity_list(model, X_test, y_test, y_pred_proba, X_test_original, output_dir, file_suffix, segment_averages, best_contact_info):\n",
        "    print(f\"\\n--- Generating Customer Propensity List ({file_suffix}) ---\")\n",
        "    results_df = X_test_original.copy()\n",
        "    results_df['propensity_to_subscribe'] = y_pred_proba\n",
        "    results_df['y_actual'] = y_test\n",
        "    results_df = bin_age(results_df)\n",
        "    results_df['total_contacts'] = results_df['previous'] + results_df['campaign']\n",
        "    results_df['recommendation'] = create_actionable_recommendations_optimized(results_df, segment_averages, best_contact_info)\n",
        "\n",
        "    # Rename columns as requested by the user\n",
        "    results_df.rename(columns={'propensity_to_subscribe': 'y_pred', 'y_actual': 'y_test'}, inplace=True)\n",
        "\n",
        "    results_df = results_df.sort_values(by='y_pred', ascending=False)\n",
        "    # Update the column order to reflect the new names\n",
        "    cols = ['y_pred', 'recommendation', 'y_test'] + [col for col in results_df.columns if col not in ['y_pred', 'recommendation', 'y_test']]\n",
        "    results_df = results_df[cols]\n",
        "    output_path = os.path.join(output_dir, f'customer_propensity_list_{file_suffix}.csv')\n",
        "    results_df.to_csv(output_path, index=False)\n",
        "    print(f\"Propensity list with actionable recommendations saved to '{output_path}'.\")\n",
        "    print(\"The CSV file contains the entire test set, ordered from highest to lowest propensity to subscribe, with a tailored marketing recommendation for each customer.\")"
      ],
      "metadata": {
        "id": "3vmGXvDxV66J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution"
      ],
      "metadata": {
        "id": "VZA5VtQ-TxTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"--- Starting Customer Propensity Model Workflow ---\")\n",
        "    data = load_bank_data()\n",
        "    if data.empty:\n",
        "        print(\"Data loading failed. Exiting.\")\n",
        "        return\n",
        "\n",
        "    prepared_df = prepare_data(data)\n",
        "\n",
        "    # We still need to engineer features on a copy of the data for the EDA plots and recommendations\n",
        "    engineered_df_for_eda = engineer_features(prepared_df.copy())\n",
        "\n",
        "    # Execute EDA on the engineered data, which still contains 'duration' for this step\n",
        "    perform_eda(engineered_df_for_eda.copy(), OUTPUT_FIGURES_DIR)\n",
        "\n",
        "    # --- Now, prepare data for model training by dropping 'duration' to prevent data leakage ---\n",
        "    print(\"\\n--- Preparing Data for Model Training ---\")\n",
        "    final_df_for_model = prepared_df.drop(columns=['duration'])\n",
        "\n",
        "    # Encode only the original features as requested\n",
        "    df_encoded, categorical_features_lgbm = encode_features(final_df_for_model)\n",
        "\n",
        "    X = df_encoded.drop(columns='y')\n",
        "    y = df_encoded['y']\n",
        "\n",
        "    # Data Split\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Train the model on original features\n",
        "    model, y_pred_proba, aucpr = train_model(\n",
        "        X_train_val, X_test, y_train_val, y_test, X_test,\n",
        "        OUTPUT_FIGURES_DIR, categorical_features_lgbm, \"Original\"\n",
        "    )\n",
        "\n",
        "    # Re-create the original training data for the segment analysis\n",
        "    df_train_subscribers_orig = prepared_df.loc[y_train_val.index].copy()\n",
        "\n",
        "    #  Convert 'y' column to numerical (0/1) for calculations\n",
        "    df_train_subscribers_orig['y'] = df_train_subscribers_orig['y'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "    # Explicitly fill NaN values in segmentation columns\n",
        "    segment_columns = ['job', 'marital', 'education', 'poutcome']\n",
        "    for col in segment_columns:\n",
        "        if df_train_subscribers_orig[col].isnull().any():\n",
        "            print(f\"Warning: NaN values found in '{col}'. Filling with 'unknown' for segmentation.\")\n",
        "            df_train_subscribers_orig[col] = df_train_subscribers_orig[col].fillna('unknown')\n",
        "\n",
        "    # Calculate segment averages and best contact times from the training data\n",
        "    # Now that 'y' is numerical, we filter for y == 1 (which means 'yes')\n",
        "    df_train_subscribers = df_train_subscribers_orig[df_train_subscribers_orig['y'] == 1].copy()\n",
        "    segment_averages = calculate_segment_averages(bin_age(df_train_subscribers))\n",
        "    best_contact_info = calculate_best_contact_info(df_train_subscribers_orig)\n",
        "\n",
        "    # Re-create the original test set for the final output and recommendations\n",
        "    X_test_original_for_final_list = prepared_df.loc[X_test.index].drop(columns=['duration'])\n",
        "\n",
        "    # Also fill NaNs in the test set's segmentation columns to match the training data\n",
        "    for col in segment_columns:\n",
        "        if X_test_original_for_final_list[col].isnull().any():\n",
        "            X_test_original_for_final_list[col] = X_test_original_for_final_list[col].fillna('unknown')\n",
        "\n",
        "    # Generate the final propensity list\n",
        "    create_propensity_list(\n",
        "        model, X_test, y_test, y_pred_proba,\n",
        "        X_test_original_for_final_list, OUTPUT_FIGURES_DIR, \"original\", segment_averages, best_contact_info\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Workflow Complete ---\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "wkpwG4QcCJHK",
        "outputId": "400d2e62-4c99-44e3-ef30-7108ec7059f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Customer Propensity Model Workflow ---\n",
            "Attempting to load data from local file: bank-full.csv\n",
            "Data loaded successfully from bank-full.csv. Shape: (45211, 17)\n",
            "Renamed 'day' to 'day_of_month' for clarity.\n",
            "No NaN values found in df.info(), so skipping NaN filling step.\n",
            "--- Performing Feature Engineering for Insights ---\n",
            "Engineered new features: 'num_existing_loans', 'has_any_loan_or_default', 'age_group', 'is_no_fixed_income', 'balance_group', 'is_negative_balance', 'was_previously_contacted', 'is_spring_summer_contact', 'total_contacts', and 'day_of_week'.\n",
            "\n",
            "--- Performing Exploratory Data Analysis (EDA) on Original Features ---\n",
            "Saved target distribution plot.\n",
            "Saved percentage plots for 18 original categorical features vs. target.\n",
            "Saved correlation matrix heatmap for all original numerical features.\n",
            "Saved duration distribution plot with mean lines.\n",
            "\n",
            "--- Preparing Data for Model Training ---\n",
            "\n",
            "--- Starting Model Training and Evaluation for Original Model ---\n",
            "Data split: Train=(27126, 15), Val=(9042, 15), Test=(9043, 15)\n",
            "Starting RandomizedSearchCV for LightGBM tuning with Early Stopping...\n",
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
            "\n",
            "Best hyperparameters found: {'subsample': 0.6, 'scale_pos_weight': 1, 'reg_lambda': 1.0, 'reg_alpha': 0.1, 'num_leaves': 31, 'n_estimators': 1000, 'min_child_samples': 30, 'max_depth': 5, 'learning_rate': 0.05, 'colsample_bytree': 1.0, 'class_weight': 'balanced'}\n",
            "Best cross-validation AUC-PR score: 0.25793415321402297\n",
            "\n",
            "Final Test Set AUC-PR for Original model: 0.4536\n",
            "\n",
            "--- Plotting Feature Importance for Original Model ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         feature  importance_percent\n",
              "5        balance           21.182004\n",
              "0            age           16.740616\n",
              "9   day_of_month           14.486645\n",
              "12         pdays            9.042506\n",
              "10         month            8.683113\n",
              "1            job            7.782412\n",
              "11      campaign            7.715858\n",
              "2        marital            3.598367\n",
              "13      previous            2.551247\n",
              "8        contact            2.280593"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6377ac0-1e54-471f-86c7-1650c913b129\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>importance_percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>balance</td>\n",
              "      <td>21.182004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>age</td>\n",
              "      <td>16.740616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>day_of_month</td>\n",
              "      <td>14.486645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>pdays</td>\n",
              "      <td>9.042506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>month</td>\n",
              "      <td>8.683113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>job</td>\n",
              "      <td>7.782412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>campaign</td>\n",
              "      <td>7.715858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>marital</td>\n",
              "      <td>3.598367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>previous</td>\n",
              "      <td>2.551247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>contact</td>\n",
              "      <td>2.280593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6377ac0-1e54-471f-86c7-1650c913b129')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6377ac0-1e54-471f-86c7-1650c913b129 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6377ac0-1e54-471f-86c7-1650c913b129');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-912df792-88df-4533-8199-472ab0f68b9f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-912df792-88df-4533-8199-472ab0f68b9f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-912df792-88df-4533-8199-472ab0f68b9f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    main()\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"previous\",\n          \"age\",\n          \"job\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"importance_percent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.288603316481645,\n        \"min\": 2.28059277664389,\n        \"max\": 21.18200372703878,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.5512467832105776,\n          16.74061584878871,\n          7.782411926524093\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature importance plot saved to 'reports/figures/feature_importance_Original.png'.\n",
            "\n",
            "--- Generating Customer Propensity List (original) ---\n",
            "Propensity list with actionable recommendations saved to 'reports/figures/customer_propensity_list_original.csv'.\n",
            "The CSV file contains the entire test set, ordered from highest to lowest propensity to subscribe, with a tailored marketing recommendation for each customer.\n",
            "\n",
            "--- Workflow Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note on importance percentage -\n",
        "\n",
        "balance\t21.182004 - This means that the customer's balance is responsible for over 21% of the model's overall predictive power in determining whether a customer will subscribe to a term deposit."
      ],
      "metadata": {
        "id": "xtgUCP6s9J8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MARKETING STRATEGY RECOMMENDATIONS (based on feature importance)**\n",
        "\n",
        "The features with the highest importance indicate the factors that most significantly influence a customer's propensity to subscribe. Focusing marketing efforts on these areas can lead to more effective campaigns.\n",
        "\n",
        "1. Target Customers Based on Financial Balance:\n",
        "    * Insight: balance is the second most important feature. Customers with higher balances might be more receptive or have more disposable income/savings.\n",
        "    * Recommendation: Prioritize customers with higher account balances for marketing efforts. Tailor offers to resonate with their financial standing.\n",
        "2. Strategic Timing of Campaigns (Day and Month):\n",
        "    * Insight: day_of_week and month are highly influential. The specific time a customer is contacted plays a crucial role.\n",
        "    * Recommendation: Analyze historical data to identify the most effective days of the week and months for outreach. Schedule campaigns to align with these optimal times to maximize response rates.\n",
        "3. Age-Based Segmentation:\n",
        "    * Insight: age is a significant demographic factor.\n",
        "    * Recommendation: Segment the customer base by age groups and develop age-specific marketing messages and product offerings that resonate with different generations.\n",
        "4. Leverage Past Contact History (pdays):\n",
        "    * Insight: pdays (number of days since last contact from previous campaign) is important.\n",
        "    * Recommendation: Understand the optimal re-engagement window. Customers who were contacted a certain number of days ago might be more or less receptive. Tailor follow-up strategies based on their prior interaction recency.\n",
        "5. Customize by Occupation (job) and Education:\n",
        "    * Insight: job and education are important demographic features.\n",
        "    * Recommendation: Develop targeted marketing messages and product positioning that align with the specific needs, financial situations, and educational backgrounds of different professional groups.\n",
        "7. Optimize Campaign Contact Frequency (campaign):\n",
        "    * Insight: campaign (number of contacts during the current campaign) is relevant. While more contacts can sometimes increase propensity, there's often a point of diminishing returns or even negative impact (customer annoyance).\n",
        "    * Recommendation: Carefully monitor and optimize the number of times a customer is contacted within a single campaign. Avoid over-contacting, as it can lead to customer fatigue and negative sentiment.\n",
        "8. Evaluate Contact Channel Effectiveness (contact):\n",
        "    * Insight: contact method (e.g., cellular, telephone) is important.\n",
        "    * Recommendation: Analyze which communication channels yield the best results for different customer segments and allocate resources accordingly.\n",
        "\n"
      ],
      "metadata": {
        "id": "PVOo1cdc1vCH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "d5b0c5b1",
        "outputId": "662a59d3-9d3c-48a6-a321-73a9346f3766"
      },
      "source": [
        "'''\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "OUTPUT_FIGURES_DIR = os.path.join(\"reports\", \"figures\")\n",
        "\n",
        "if os.path.exists(OUTPUT_FIGURES_DIR):\n",
        "    shutil.rmtree(OUTPUT_FIGURES_DIR)\n",
        "    print(f\"Deleted directory: {OUTPUT_FIGURES_DIR}\")\n",
        "else:\n",
        "    print(f\"Directory not found: {OUTPUT_FIGURES_DIR}\")\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\nimport shutil\\n\\nOUTPUT_FIGURES_DIR = os.path.join(\"reports\", \"figures\")\\n\\nif os.path.exists(OUTPUT_FIGURES_DIR):\\n    shutil.rmtree(OUTPUT_FIGURES_DIR)\\n    print(f\"Deleted directory: {OUTPUT_FIGURES_DIR}\")\\nelse:\\n    print(f\"Directory not found: {OUTPUT_FIGURES_DIR}\")\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}